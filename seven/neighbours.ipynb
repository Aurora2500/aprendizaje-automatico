{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica siete\n",
    "\n",
    "Grupo 14:\n",
    "* Joaquín Ibáñez Penalva\n",
    "* Aurora Zuoris\n",
    "\n",
    "Para la realización de esta práctica se usará la librería de numpy, pandas, matplotlib, y sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('precio_casas_clasificacion.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apartado 1\n",
    "\n",
    "X = data.drop('Precio', axis=1) # Eliminamos la columna precio\n",
    "y = data['Precio'] # Obtenemos la columna precio\n",
    "X.head() # Mostramos las 5 primeras filas de X\n",
    "y.head() # Mostramos las 5 primeras filas de y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Dividimos los datos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apartado 2\n",
    "\n",
    "for i in range(1, 21): # Probamos con 20 vecinos\n",
    "    knn = KNeighborsClassifier(n_neighbors=i) # Creamos el modelo\n",
    "    knn.fit(X_train, y_train) # Entrenamos el modelo\n",
    "    y_pred = knn.predict(X_test) # Predecimos los valores\n",
    "    print(f'K={i:>2} -> Accuracy: {accuracy_score(y_test, y_pred):.5f}') # Mostramos el accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apartado 3\n",
    "\n",
    "scaler = MinMaxScaler() # Creamos el objeto scaler para escalar los datos entre 0 y 1\n",
    "X_train_scaled = scaler.fit_transform(X_train) # Escalamos los datos de entrenamiento\n",
    "X_test_scaled = scaler.transform(X_test) # Escalamos los datos de test\n",
    "\n",
    "Max_accuracy_apart3 = 0 # Variable para almacenar el accuracy máximo\n",
    "\n",
    "for i in range(1, 21): # Probamos con 20 vecinos\n",
    "    knn = KNeighborsClassifier(n_neighbors=i) # Creamos el modelo con el número de vecinos vecinos que queremos probar (i)\n",
    "    knn.fit(X_train_scaled, y_train) # Entrenamos el modelo\n",
    "    y_pred = knn.predict(X_test_scaled) # Predecimos los valores\n",
    "    print(f'K={i:>2} -> Accuracy scaled: {accuracy_score(y_test, y_pred):.5f}') # Mostramos el accuracy\n",
    "    if accuracy_score(y_test, y_pred) > Max_accuracy_apart3:\n",
    "        Max_accuracy_apart3 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede comprobar la tasa de acierto cuando está escalado es bastante mayor que cuando no lo está, ya que así nos aseguramos de que todo esté en la misma orden de magnitud por lo que todas las variables tienen la misma importancia independientemente de su escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apartado 4\n",
    "# Calcular tiempo de ejecución del apartado 3 para ball_tree, kd_tree y brute y printearlo\n",
    "\n",
    "import time\n",
    "\n",
    "inicio = time.time() # Guardamos el tiempo de inicio de la ejecución\n",
    "\n",
    "for j in range(1, 5): # Probamos con 4 iteraciones\n",
    "    for i in range(1, 21):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i, algorithm='ball_tree') \n",
    "        knn.fit(X_train_scaled, y_train)\n",
    "        y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "fin = time.time() # Guardamos el tiempo de fin de la ejecución\n",
    "print(f'Tiempo de ejecución ball tree: {fin - inicio:.5f}') # Mostramos el tiempo de ejecución\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "for j in range(1, 5):\n",
    "    for i in range(1, 21):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i, algorithm='kd_tree')\n",
    "        knn.fit(X_train_scaled, y_train)\n",
    "        y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "fin = time.time()\n",
    "print(f'Tiempo de ejecución kd tree: {fin - inicio:.5f}')\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "for j in range(1, 5):\n",
    "    for i in range(1, 21):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i, algorithm='brute')\n",
    "        knn.fit(X_train_scaled, y_train)\n",
    "        y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "fin = time.time()\n",
    "print(f'Tiempo de ejecución brute: {fin - inicio:.5f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El que más tarda es el de ball tree con 50 segundos aprox y el que menos el de kd tree con 18 segundos aprox. El brute tarda 25 segundos aprox, menos que el ball tree pero más que el kd tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apartado 5\n",
    "\n",
    "X_train_5, X_val, y_train_5, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42) # Dividimos los datos de entrenamiento en train y validación (80% train y 20% validación)\n",
    "\n",
    "print(\"------------ KNN con pesos uniformes --------------\")\n",
    "\n",
    "Max_accuracy_uniform = 0 # Variable para almacenar el accuracy máximo con pesos uniformes\n",
    "Max_accuracy_k_uniform = 0 # Variable para almacenar el k con el que se obtiene el accuracy máximo con pesos uniformes\n",
    "\n",
    "for i in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, weights='uniform') # Probamos con pesos uniformes\n",
    "    knn.fit(X_train_5, y_train_5)\n",
    "    y_pred = knn.predict(X_val)\n",
    "    print(f'K={i:>2} -> Accuracy scaled weights = uniform: {accuracy_score(y_val, y_pred):.5f}')\n",
    "    if accuracy_score(y_val, y_pred) > Max_accuracy_uniform: # Si el accuracy es mayor que el máximo actual, lo guardamos\n",
    "        Max_accuracy_uniform = accuracy_score(y_val, y_pred) # Guardamos el accuracy máximo\n",
    "        Max_accuracy_k_uniform = i # Guardamos el k con el que se obtiene el accuracy máximo\n",
    "\n",
    "print(\"------------ KNN con pesos inversamente proporcionales a la distancia --------------\")\n",
    "\n",
    "Max_accuracy_distance = 0 # Variable para almacenar el accuracy máximo con pesos inversamente proporcionales a la distancia\n",
    "Max_accuracy_k_distance = 0 # Variable para almacenar el k con el que se obtiene el accuracy máximo con pesos inversamente proporcionales a la distancia\n",
    "\n",
    "for i in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, weights='distance') # Probamos con pesos inversamente proporcionales a la distancia (más cercanos tienen más peso)\n",
    "    knn.fit(X_train_5, y_train_5)\n",
    "    y_pred = knn.predict(X_val)\n",
    "    print(f'K={i:>2} -> Accuracy scaled weights = distance: {accuracy_score(y_val, y_pred):.5f}')\n",
    "    if accuracy_score(y_val, y_pred) > Max_accuracy_distance:\n",
    "        Max_accuracy_distance = accuracy_score(y_val, y_pred)\n",
    "        Max_accuracy_k_distance = i\n",
    "\n",
    "print(f'El mejor accuracy con pesos uniformes es {Max_accuracy_uniform:.5f} con k = {Max_accuracy_k_uniform}')\n",
    "print(f'El mejor accuracy con pesos inversamente proporcionales a la distancia es {Max_accuracy_distance:.5f} con k = {Max_accuracy_k_distance}')\n",
    "\n",
    "if Max_accuracy_uniform > Max_accuracy_distance: # Comparamos los accuracy máximos para ver cuál es el mejor modelo\n",
    "    best_k = Max_accuracy_k_uniform\n",
    "    best_weights = 'uniform'\n",
    "    print(f'El mejor modelo es con pesos uniformes es y k = {best_k}')\n",
    "else:\n",
    "    best_k = Max_accuracy_k_distance\n",
    "    best_weights = 'distance'\n",
    "    print(f'El mejor modelo es con pesos inversamente proporcionales a la distancia y k = {best_k}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_k, weights=best_weights) # Creamos el modelo con el mejor k y los mejores pesos (uniform o distance, en este caso distance)\n",
    "knn.fit(X_train_scaled, y_train) # Entrenamos el modelo\n",
    "y_pred = knn.predict(X_test_scaled) # Predecimos los valores\n",
    "print(f'Accuracy final: {accuracy_score(y_test, y_pred):.5f}') # Mostramos el accuracy\n",
    "\n",
    "print(f'Max_accuracy_apart3: {Max_accuracy_apart3:5.f}') # Mostramos el accuracy máximo del apartado 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "124093b7be10c32076c75f60f415d6def65edeb693f6c465ae4e1e508e9d8137"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
