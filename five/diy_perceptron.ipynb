{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica cinco\n",
    "\n",
    "Grupo 14:\n",
    "* Joaquín Ibáñez Penalva\n",
    "* Aurora Zuoris\n",
    "\n",
    "Para la realización de esta práctica se usará la librería de numpy, pandas, matplotlib, y sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, max_iter=1000, mezclar=True, eta=1.0, random_state=42):\n",
    "    \"\"\"\n",
    "    max_iter: cantidad máxima de iteraciones\n",
    "    mezclar: si se mezclan los datos\n",
    "    eta: tasa de aprendizaje\n",
    "    random_state: semilla para el generador de números aleatorios\n",
    "    \"\"\"\n",
    "    self._max_iter = max_iter\n",
    "    self._mezclar = mezclar\n",
    "    self._eta = eta\n",
    "    self._random_state = random_state\n",
    "\n",
    "  def ajustar(self, X, y):\n",
    "    \"\"\"\n",
    "    X: matriz de variables predictoras\n",
    "    y: vector de variables clasificadas\n",
    "    \"\"\"\n",
    "\n",
    "    # nos aseguramos que las dimensiones de X, y, y que concuerden en número de muestras.\n",
    "    if len(X.shape) != 2:\n",
    "      raise ValueError(\"X debe ser una matriz bidimensional\")\n",
    "    if len(y.shape) != 1:\n",
    "      raise ValueError(\"y debe ser un vector\")\n",
    "    if X.shape[0] != y.shape[0]:\n",
    "      raise ValueError(\"X y y deben tener la misma cantidad de filas\")\n",
    "\n",
    "    # La implementación actual solo puede soportar dos clases diferentes.\n",
    "    if len(np.unique(y)) != 2:\n",
    "      raise ValueError(\"y debe tener dos clases\")\n",
    "\n",
    "    # Codifica las etiquetas.\n",
    "    self._le = LabelEncoder().fit(y)\n",
    "    encoded_y = self._le.transform(y)\n",
    "\n",
    "    n, m = X.shape # n: cantidad de muestras, m: cantidad de variables predictoras\n",
    "\n",
    "    weights = np.zeros(m)\n",
    "    bias = 0\n",
    "\n",
    "    # Itera como máximo self._max_iter veces.\n",
    "    for _ in range(self._max_iter):\n",
    "      if self._mezclar:\n",
    "        X, encoded_y = self._shuffle(X, encoded_y)\n",
    "\n",
    "      # calculamos la salida del perceptrón actual.\n",
    "      res = np.dot(X, weights) + bias\n",
    "      res_sign = np.sign(res)\n",
    "      res_sign[res_sign == 0] = -1 # si el signo de res es cero, lo convierte en -1\n",
    "      # calculamos donde se equivoca, es decir, donde la salida del perceptrón no coincide con la salida esperada.\n",
    "      errors = ((res_sign == 1) != (encoded_y == 1))\n",
    "      # si no queda ningun error en la clasificación, terminamos.\n",
    "      if np.all(~errors):\n",
    "        break\n",
    "      errors_sign = np.where(errors, np.where(res_sign == 1, -1, 1), 0) # calcula el signo de los errores\n",
    "      delta_bias = self._eta * np.sum(errors_sign) # calcula el cambio de bias\n",
    "      delta_weights = self._eta * np.dot(errors_sign, X) # calcula el cambio de weights\n",
    "      bias += delta_bias # actualiza bias\n",
    "      weights += delta_weights # actualiza weights\n",
    "    self.pesos_ = weights # guarda los pesos\n",
    "    self.pesos_umbral_ = bias # guarda el peso umbral\n",
    "    return self # devuelve el objeto\n",
    "\n",
    "  def predecir(self, X): # X: matriz bidimensional\n",
    "    y_code =  np.dot(X, self.pesos_) + self.pesos_umbral_ > 0 # calcula el producto punto de X y los pesos y le suma el peso umbral y compara si es mayor a cero\n",
    "    y_code = np.where(y_code, 1, 0) # si y_code es True, lo convierte en 1, si es False, lo convierte en 0\n",
    "    return self._le.inverse_transform(y_code) # convierte las codificaciones de y_code en sus etiquetas\n",
    "\n",
    "\n",
    "  def _shuffle(self, X, y): # mezcla X e y\n",
    "    n, _ = X.shape # n: cantidad de filas de X, _: cantidad de columnas de X\n",
    "    rng = np.random.RandomState(self._random_state) # crea un generador de números aleatorios\n",
    "    idx = rng.permutation(n) # crea un vector con los índices de las filas de X en orden aleatorio\n",
    "    \n",
    "    # Se convierte los predictores a numpy para poder indexarlos con idx.\n",
    "    if(type(X) == pd.DataFrame):\n",
    "      X = X.to_numpy()\n",
    "    return X[idx], y[idx] # devuelve X e y con las filas en orden aleatorio\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris_pca_2d.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separan los datos segun las clases de primeras.\n",
    "classes = set(df['clase'].unique())\n",
    "split_classes = [classes - {c} for c in classes]\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "pc1_range = np.linspace(df['pc1'].min(), df['pc1'].max(), 100)\n",
    "\n",
    "for i, c in enumerate(split_classes):\n",
    "  class_to_col = {cl: co for co, cl in zip(('red', 'blue'), c)}\n",
    "  local_df = df[df['clase'].isin(c)]\n",
    "  x_train, x_test, y_train, y_test = train_test_split(local_df[['pc1', 'pc2']], local_df['clase'], test_size=0.3, random_state=42)\n",
    "  perceptron = Perceptron(max_iter=50_000).ajustar(x_train, y_train)\n",
    "\n",
    "  line = - (perceptron.pesos_[0] / perceptron.pesos_[1]) * pc1_range - (perceptron.pesos_umbral_ / perceptron.pesos_[1])\n",
    "\n",
    "  axs[i, 0].scatter(x_train['pc1'], x_train['pc2'], c=y_train.map(lambda x: class_to_col[x]), label=y_train.unique())\n",
    "  axs[i, 1].scatter(x_test['pc1'], x_test['pc2'], c=y_test.map(lambda x: class_to_col[x]), label=y_test)\n",
    "\n",
    "  axs[i, 0].plot(pc1_range, line, 'k-')\n",
    "  axs[i, 1].plot(pc1_range, line, 'k-')\n",
    "\n",
    "  axs[i, 0].set_ylim(df['pc2'].min(), df['pc2'].max())\n",
    "  axs[i, 1].set_ylim(df['pc2'].min(), df['pc2'].max())\n",
    "\n",
    "  legend_elems = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label=c, markerfacecolor=class_to_col[c], markersize=10)\n",
    "    for c in c\n",
    "  ]\n",
    "\n",
    "  axs[i, 0].legend(handles=legend_elems)\n",
    "  axs[i, 1].legend(handles=legend_elems)\n",
    "\n",
    "  name = '-'.join(c)\n",
    "\n",
    "  yhat = perceptron.predecir(x_test)\n",
    "  score = accuracy_score(y_test, yhat)\n",
    "\n",
    "  axs[i, 0].set_title(f'Entrenamiento {name}')\n",
    "  axs[i, 1].set_title(f'Test {name} (concuerdan {score:.2%})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
