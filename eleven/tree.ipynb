{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica once\n",
    "\n",
    "Grupo 14:\n",
    "* Joaquín Ibáñez Penalva\n",
    "* Aurora Zuoris\n",
    "\n",
    "Para la realización de esta práctica se usará la librería de numpy, pandas, matplotlib, y sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wisconsin diagnostic breast cancer.csv')\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Crear el modelo de árbol de decisión\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir la clase de los datos de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc2 = cross_val_score(model, X, y, cv=10).mean()\n",
    "print(f\"Accuracy del modelo por defecto: {acc:.3f}\")\n",
    "print(f\"Accuracy del modelo con validación cruzada: {acc2:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada lo que hace es hacer la división de datos en train y test varias veces, y calcular la media de los resultados. Esto es útil para evitar que el resultado dependa de la partición de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Definir los valores de los parámetros a explorar\n",
    "param_grid = {\n",
    "    'max_depth': range(1, 10),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "}\n",
    "\n",
    "# Crear el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid=param_grid, scoring='recall', cv=10)\n",
    "y_train_bool = y_train == 'M'\n",
    "# Entrenar el objeto GridSearchCV\n",
    "grid_search.fit(X_train, y_train_bool)\n",
    "\n",
    "\n",
    "# Obtener los mejores parámetros y la accuracy correspondiente\n",
    "best_params = grid_search.best_params_\n",
    "best_acc = grid_search.best_score_\n",
    "\n",
    "print(f\"Mejores parámetros: {best_params}\")\n",
    "print(f\"Accuracy con los mejores parámetros: {best_acc:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede comprobar, fijandose en poner los mejores parámetros el accuracy es de 0.96% practicamente, mientras que con un árbol por defecto es de 0.93% usando validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "tree = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=tree.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser un tema medico, nos hemos fijado en el mejor arbol teniendo en cuenta que tenga la menor tasa de falsos negativos posible, ya que es peor que un paciente tenga cancer y no se le diagnostique, que un paciente que no tenga cancer y se le diagnostique. Esto queda demostrado con la matriz de confusión, que da 0 en falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mostrar gráficamente los árboles obtenidos con los parámetros por defecto y los mejores hiperparámetros\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(2,1,1)\n",
    "plot_tree(tree, filled=True)\n",
    "plt.title(\"Árbol de decisión con mejores hiperparámetros\")\n",
    "plt.subplot(2,1,2)\n",
    "plot_tree(model, filled=True)\n",
    "plt.title(\"Árbol de decisión con parámetros por defecto\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de ser mejor el arbol con los mejores parámetros, es más sencillo de interpretar, ya que tiene menos nodos y menor profundidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree score: 94.74%\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "print(f'Decision tree score: {dt.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " array([False,  True, False, False, False, False, False,  True, False,\n",
       "        False, False, False, False,  True,  True, False,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True, False, False,\n",
       "         True, False, False]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_features = dt.feature_importances_ > 0\n",
    "used_count = np.sum(used_features)\n",
    "used_count, used_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score: 95.61%\n"
     ]
    }
   ],
   "source": [
    "X_train_tree = X_train[:, used_features]\n",
    "X_test_tree = X_test[:, used_features]\n",
    "\n",
    "svc = SVC(random_state=42).fit(X_train_tree, y_train)\n",
    "print(f'SVM score: {svc.score(X_test_tree, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=used_count)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_mut = selector.transform(X_train)\n",
    "X_test_mut = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score: 94.74%\n"
     ]
    }
   ],
   "source": [
    "svc2 = SVC(random_state=42).fit(X_train_mut, y_train)\n",
    "print(f'SVM score: {svc2.score(X_test_mut, y_test):.2%}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que el uso del arbol de decision para seleccionar las características da un resultado marginalmente (95.61% vs 94.74%, menos de 1% de differencia) mejor que el uso de filtrado mediante información mutua.\n",
    "\n",
    "Para llegar a una conclusión más informativa, se utilizará cross validation para obtener el rendimiento medio de cada método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desicion trees: 93.85% ± 1.79%\n",
      "SVM: 91.39% ± 2.88%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_tree = X[:, used_features]\n",
    "X_mut = selector.transform(X)\n",
    "\n",
    "scores1 = cross_val_score(svc, X_tree, y, cv=10)\n",
    "scores2 = cross_val_score(svc2, X_mut, y, cv=10)\n",
    "\n",
    "print(f'Desicion trees: {scores1.mean():.2%} ± {scores1.std():.2%}')\n",
    "print(f'SVM: {scores2.mean():.2%} ± {scores2.std():.2%}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último se utiliza un test de T de Student para ver si la diferencia de rendimiento es significativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.84%\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "# t-test mediante solo numpy: https://stackoverflow.com/a/44763186\n",
    "diff = scores2 - scores1\n",
    "\n",
    "t = diff.mean() / diff.std(ddof=1) * np.sqrt(len(diff))\n",
    "s = np.random.standard_t(len(diff), size=10_000_000)\n",
    "p = np.sum(s<t) / float(len(s))\n",
    "prob = 2 * min(p, 1-p)\n",
    "print(f'p-value: {prob:.2%}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El p-valor es de 0.84%, por lo que se puede concluir que la diferencia de rendimiento entre estos dos métodos de selección de característica es significativa.\n",
    "De forma que usar el arbol de decisión para seleccionar las características es mejor que usar filtrado mediante información mutua.\n",
    "Esto se puede razonar con que el uso de un arbol de decisión es más computacionalmente costoso, por lo que se puede esperar que de mejores resultados.\n",
    "Además, la filtración no tiene en cuenta la relación entre las características, mientras que el arbol de decisión sí.\n",
    "\n",
    "Otra perspectiva que podemos utilizar para este análisis es ver en qué concuerdan y en qué difieren los resultados de ambos métodos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los dos métodos concuerdan en 5 características (Mean concave points, Standard Error area, Worst radius, Worst perimeter, Worst concave points)\n",
      "\n",
      "El árbol de decisión eligió además estas características: Mean texture, Standard Error smoothness, Standard Error concavity, Standard Error concave points, Standard Error fractal dimension, Worst texture, Worst smoothness\n",
      "\n",
      "Y el método de filtrado eligió estas otras: Mean radius, Mean perimeter, Mean area, Mean concavity, Standard Error radius, Worst area, Worst concavity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_features = set(np.where(used_features)[0])\n",
    "filter_features = set(np.where(selector.get_support())[0])\n",
    "\n",
    "common = tree_features & filter_features\n",
    "common_names = \", \".join(data.columns[2:][list(common)])\n",
    "\n",
    "tree_names = \", \".join(data.columns[2:][list(tree_features - common)])\n",
    "filter_names = \", \".join(data.columns[2:][list(filter_features - common)])\n",
    "\n",
    "print(f\"Los dos métodos concuerdan en {len(common)} características ({common_names})\\n\")\n",
    "print(f\"El árbol de decisión eligió además estas características: {tree_names}\\n\")\n",
    "print(f\"Y el método de filtrado eligió estas otras: {filter_names}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c900cb90dee983911779de55d7a1efccb46f16c81cdf15a7b8ee95d3de3d3b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
