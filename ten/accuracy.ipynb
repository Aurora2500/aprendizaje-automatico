{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica diez\n",
    "\n",
    "Grupo 14:\n",
    "* Joaquín Ibáñez Penalva\n",
    "* Aurora Zuoris\n",
    "\n",
    "Para la realización de esta práctica se usará la librería de numpy, pandas, matplotlib, y sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('CelebA-10K-train.csv')\n",
    "data_test = pd.read_csv('CelebA-10K-test.csv')\n",
    "\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.iloc[:, 2:]\n",
    "y_train = data_train.iloc[:, 1]\n",
    "X_test = data_test.iloc[:, 2:]\n",
    "y_test = data_test.iloc[:, 1]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "classifs = [\n",
    "\t('Regresión Logística', LogisticRegression()),\n",
    "\t('Perceptón', Perceptron()),\n",
    "\t('SVM', SVC()),\n",
    "\t('KNN(5)', KNeighborsClassifier(n_neighbors=5)),\n",
    "\t('Centroide más cercano', NearestCentroid())\n",
    "]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "table = defaultdict(list)\n",
    "\n",
    "fig, ax = plt.subplots(5, 1, figsize=(5, 25))\n",
    "\n",
    "for i, (name, model) in enumerate(classifs):\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\tcm = confusion_matrix(y_test, model.predict(X_test))\n",
    "\tConfusionMatrixDisplay(cm, display_labels=['male', 'female']).plot(ax=ax[i])\n",
    "\tax[i].set_title(name)\n",
    "\n",
    "\taccuracy = np.trace(cm) / np.sum(cm)\n",
    "\trecall = cm[1, 1] / np.sum(cm[1, :])\n",
    "\tprecision = cm[1, 1] / np.sum(cm[:, 1])\n",
    "\tspecificity = cm[0, 0] / np.sum(cm[0, :])\n",
    "\tf1_score = 2 * precision * recall / (precision + recall)\n",
    "\ttable['model'].append(name)\n",
    "\ttable['accuracy'].append(accuracy)\n",
    "\ttable['recall'].append(recall)\n",
    "\ttable['precision'].append(precision)\n",
    "\ttable['specificity'].append(specificity)\n",
    "\ttable['f1_score'].append(f1_score)\n",
    "\n",
    "pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.iloc[:,2:]\n",
    "y_train = data_train.iloc[:,1]\n",
    "X_test = data_test.iloc[:,2:]\n",
    "y_test = data_test.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attrs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=42)),\n",
    "    (\"Perceptron\", Perceptron(random_state=42)),\n",
    "    (\"SVC\", SVC(random_state=42, gamma=\"auto\")),\n",
    "    (\"Gaussian\", GaussianNB()),\n",
    "    (\"Nearest Centroid\", NearestCentroid()),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "fig2, ax2 = plt.subplots(5, 1, figsize=(5, 25))\n",
    "\n",
    "for i, (name, model) in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    p = model.predict(X_test)\n",
    "    c = confusion_matrix(y_test, p)\n",
    "    ConfusionMatrixDisplay(c, display_labels=[\"male\", \"female\"]).plot(ax=ax2[i])\n",
    "    ax2[i].set_title(name)\n",
    "\n",
    "    tn, fp, fn, tp = c.ravel()\n",
    "    \n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    ax.scatter(fpr, tpr, label=name)\n",
    "    ax.plot([0, 1], [0, 1], color=\"black\", linestyle=\"--\")\n",
    "\n",
    "ax.set_xlabel(\"FPR\")\n",
    "ax.set_ylabel(\"TPR\")\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar con la regresión logística es la que mayor ratio de verdaderos positivos tiene, así como la que menor ratio de falsos positivos tiene. Por lo tanto, es la que mejor clasifica los datos. Por otro lado, la Gausiana es la que peor clasifica los datos, ya que tiene el menor ratio de verdaderos positivos y el segundo mayor ratio de falsos positivos, solo por detrás del Nearest Centroid, sin embargo el Nearest Centroid al menos tiene una tasa de verdaderos positivos prácticamente igual que el de la regresión logística."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linspace\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifs = [\n",
    "\t('Naive Bayes', GaussianNB()),\n",
    "\t('Regresión Logística', LogisticRegression()),\n",
    "\t('SVM', SVC(probability=True))\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "for name, model in classifs:\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\tprobs = model.predict_proba(X_test)[:, 0]\n",
    "\tspace = np.linspace(0, 1, 100)\n",
    "\thits = (probs < space[:, None]) == (y_test == model.classes_[0])[:,None]\n",
    "\tax.plot(space, np.sum(hits, axis=0) / len(probs), label=name)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Aleatorio')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('Curvas ROC')\n",
    "fig.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "124093b7be10c32076c75f60f415d6def65edeb693f6c465ae4e1e508e9d8137"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
